{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":224751288,"sourceType":"kernelVersion"},{"sourceId":224752987,"sourceType":"kernelVersion"}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#-- Import libraries ------------------------------------------------------------------------------------------------------\nimport os\nimport cv2\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n#---------------------------------------------------------------------------------------------------------------------------","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Initialize -------------------------------------------------------------------------------------------------------------\nbatch_size = 2000\nbatch_number = 0\nN_BACKS = 5\ndarkening_factor = 0.2\n\nbackgrounds_path = \"/kaggle/input/n-drone-clear-backs/backgrounds/\"  \ndrones_path = \"/kaggle/input/n-drone-clear-drones/drones/\"  \noutput_path = f\"dataset_no_scale_part_{batch_number+1}\"  \n\nos.makedirs(output_path, exist_ok=True)\nos.makedirs(os.path.join(output_path, \"images\"), exist_ok=True)\nos.makedirs(os.path.join(output_path, \"labels\"), exist_ok=True)\n#---------------------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- get all backgrounds and drones as 2 lists ------------------------------------------------------------------------------\nbackgrounds = [os.path.join(backgrounds_path, f) for f in os.listdir(backgrounds_path)]            \ndrones = [os.path.join(drones_path, f) for f in os.listdir(drones_path)]\n\nbackgrounds = sorted(backgrounds)\ndrones = sorted(drones)\n\nprint(f'number of background images: {len(backgrounds)}')\nprint(f'number of drone images: {len(drones)}')\n#---------------------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- set batch ---------------------------------------------------------------------------------------------------------------\ntotal_drones = len(drones)  \nif total_drones == 0:\n    raise ValueError(\"No drones found in the dataset!\")\n\ndrones_per_batch = max(1, batch_size // N_BACKS)  \nnum_batches = (total_drones + drones_per_batch - 1) // drones_per_batch  \n\nstart_idx = batch_number * drones_per_batch\nend_idx = min(start_idx + drones_per_batch, total_drones)  \n\nprint(f\"Processing batch {batch_number + 1}/{num_batches}, drones {start_idx} to {end_idx - 1}\")\n#---------------------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Function to add drone object to background image -----------------------------------------------------------------------\ndef add_object_to_background(background_img, object_img, x, y):\n    \n    object_h, object_w = object_img.shape[:2]\n    \n    #-- Crop the region of interest (ROI) from the background with the same size as the object --\n    roi = background_img[y:y+object_h, x:x+object_w]\n\n    #-- Extract the alpha channel as a mask --\n    object_rgb = object_img[:, :, :3]  #-- RGB channels (BGR)\n    mask = object_img[:, :, 3] / 255.0  #-- Normalize alpha channel to the range [0,1]\n\n    #-- Blend the object with the background based on the alpha mask --\n    for c in range(3):  # For each color channel (BGR)\n        roi[:, :, c] = (1 - mask) * roi[:, :, c] + mask * object_rgb[:, :, c]\n\n    # --Place the modified region back into the original background--\n    background_img[y:y+object_h, x:x+object_w] = roi\n    return background_img\n#---------------------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Function to Displaye Result of Blending Drone and background -----------------------------------------------------------\ndef show_image_with_bbox(image, x_center, y_center, w_norm, h_norm, title):\n    img_with_bbox = image.copy()\n    h, w, _ = img_with_bbox.shape      \n    \n    bbox_width = int(w_norm * w)\n    bbox_height = int(h_norm * h)\n    x_min = int((x_center * w) - (bbox_width / 2))\n    y_min = int((y_center * h) - (bbox_height / 2))\n    x_max = x_min + bbox_width\n    y_max = y_min + bbox_height\n    \n    color = (0, 0, 255)  \n    thickness = 2 \n    cv2.rectangle(img_with_bbox, (x_min, y_min), (x_max, y_max), color, thickness)\n    \n    plt.figure(figsize=(8, 8))\n    plt.imshow(cv2.cvtColor(img_with_bbox, cv2.COLOR_BGR2RGB)) \n    plt.axis(\"off\")\n    plt.title(title)\n    plt.show()\n#---------------------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#-- Run --------------------------------------------------------------------------------------------------------------------\ncount = 0  \n\nfor i in range(start_idx+50, end_idx):\n    drone = drones[i]\n    selected_backgrounds = random.sample(backgrounds, min(N_BACKS, len(backgrounds)))  \n    \n    for j, background in enumerate(selected_backgrounds):\n        if count >= batch_size:\n            break  \n\n        if count % 100 == 0:\n            print(f'Processing {count + 1}th item: {drone} with {background}')\n\n        background_path = selected_backgrounds[j]\n        drone_path = drone        \n\n        background_img = cv2.imread(background_path)        \n        drone_img = cv2.imread(drone_path, cv2.IMREAD_UNCHANGED)\n\n        plt.figure(figsize=(3, 3))\n        plt.imshow(cv2.cvtColor(drone_img, cv2.COLOR_BGR2RGB)) \n        plt.axis(\"off\")\n        plt.show()\n\n        plt.figure(figsize=(8, 8))\n        plt.imshow(cv2.cvtColor(background_img, cv2.COLOR_BGR2RGB)) \n        plt.axis(\"off\")\n        plt.show()\n            \n        if background_img is None or drone_img is None:\n            print(f'NONE: {background_path}\\n{drone_path}')\n            continue   \n        \n            \n        #-- Darken drone_img --        \n        if drone_img.shape[-1] == 4:            \n            #-- Split channels --\n            bgr_channels = drone_img[:, :, :3]  #-- Extract RGB/BGR channels\n            alpha_channel = drone_img[:, :, 3]  #-- Extract the alpha channel\n        \n            #-- Create a mask where alpha > 0 (non-transparent areas) --\n            mask = alpha_channel > 0  \n        \n            #-- Darken only the non-transparent areas (scaling towards black) --             \n            bgr_channels[mask] = (bgr_channels[mask].astype(np.float32) * darkening_factor).astype(np.uint8)\n        \n            #-- Merge back with the unchanged alpha channel --\n            drone_img = cv2.merge((bgr_channels, alpha_channel))\n        \n        else: #-- If there's no alpha channel, just darken the whole image            \n            drone_img = (drone_img.astype(np.float32) * darkening_factor).astype(np.uint8)        \n\n        background_h, background_w, _ = background_img.shape\n        drone_h, drone_w, _ = drone_img.shape\n\n        #-- set scale factor based on ratio --\n        ratio_w = drone_w / background_w  \n        ratio_h = drone_h / background_h  \n        ratio = min(ratio_w, ratio_h)   \n        ratio = round(ratio,2)  \n\n        if ratio <0.04:\n            continue\n        elif ratio>=0.04 and ratio<=0.05:\n            scale_factor = round(random.uniform(0.8,0.9), 2)  \n        elif ratio>0.05 and ratio<=0.1:\n            scale_factor = round(random.uniform(0.5,0.7), 2)  \n        elif ratio>0.1 and ratio<=0.2:\n            scale_factor = round(random.uniform(0.4,0.6), 2)  \n        elif ratio>0.2 and ratio<=0.3:\n            scale_factor = round(random.uniform(0.3,0.5), 2)  \n        elif ratio>0.3 and ratio<=0.4:\n            scale_factor = round(random.uniform(0.2,0.4), 2)  \n        else: # >0.4\n            scale_factor = round(random.uniform(0.1,0.2), 2)  \n\n        new_w = int(drone_w * scale_factor)\n        new_h = int(drone_h * scale_factor)\n        drone_img = cv2.resize(drone_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n        drone_h, drone_w, _ = drone_img.shape            \n\n        #-- Select a random location to place the object --\n        x_min = random.randint(0, background_w - drone_w)\n        y_min = random.randint(0, background_h - drone_h)\n        x_max = x_min + drone_w\n        y_max = y_min + drone_h        \n            \n        #-- Insert the object image onto the background with transparency --\n        background_with_obj = background_img.copy()\n        background_with_obj = add_object_to_background(background_with_obj,\n                                                           drone_img,\n                                                           x_min, y_min)\n    \n        #-- Calculate the Bounding Box in YOLO format --\n        x_center = (x_min + x_max) / 2 / background_w\n        y_center = (y_min + y_max) / 2 / background_h\n        w_norm = drone_w / background_w\n        h_norm = drone_h / background_h\n    \n        #-- Save the result image --\n        output_img_name = f\"{os.path.basename(drone_path).split('.')[0]}_{scale_factor}_{os.path.basename(background_path).split('.')[0]}.jpg\"\n        output_img_path = os.path.join(output_path, \"images\", output_img_name)\n        os.makedirs(os.path.dirname(output_img_path), exist_ok=True)  \n        cv2.imwrite(output_img_path, background_with_obj)\n    \n        #-- Save the YOLO file --\n        output_txt_name = output_img_name.replace(\".jpg\", \".txt\")\n        output_txt_path = os.path.join(output_path, \"labels\", output_txt_name)\n        os.makedirs(os.path.dirname(output_txt_path), exist_ok=True)\n        with open(output_txt_path, \"w\") as f:\n            f.write(f\"0 {x_center} {y_center} {w_norm} {h_norm}\\n\")           \n    \n        #-- Display the final image with the bounding box --\n        title = output_img_name\n        show_image_with_bbox(background_with_obj, x_center, y_center, w_norm, h_norm, title)\n            \n        count += 1\n        \n        if count >= batch_size:\n            break  \n    if count >= batch_size:\n        break\n#---------------------------------------------------------------------------------------------------------------------------","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}